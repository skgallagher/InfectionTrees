#!/usr/bin/env Rscript

## SKG
## July 1, 2020
## Setting up simulations for approximations of L(n)

## Here we fix a conditional tree of size n with p percent positive smears.  We then estimate L(n) -- the total contribution to the likelihood. We look at this by K -- the number of simulations


## Load libraries and data
devtools::load_all()
library(ggplot2)
library(dplyr)
library(data.table)
library(ggridge)

my_seed <- 7012020
set.seed(my_seed)

n <- 40
prop_pos <- .5
cond_df <- data.frame(cluster_id = 1, 
                 smear = c(rep(1, floor(prop_pos * n)),
                           rep(0, n - floor(prop_pos * n)))
                 )
covariate_names <- "smear"
B <- 100

B_seq <- c(100, 500, 1000, 5000, 10000)
prop_pos_seq <- c(.25, .5, .75)
list_df <- vector(mode = "list", length = length(B_seq) * length(prop_pos_seq))
for(ii in 1:length(B_seq)){
    B <- B_seq[ii]
    print(paste("B", B))
    for(jj in 1:length(prop_pos_seq)){

        prop_pos <- prop_pos_seq[jj]
        print(paste("Prop pos", prop_pos))
        


        ## Get the samples
        sampled_data_all <-  sample_permuted_cond_trees(cond_df,
                                                        B = B,
                                                        covariate_names = covariate_names)

        inf_params <- c(-2, 1.5)

        sampled_loglike_df <- general_loglike(inf_params,
                                              observed_data = cond_df,
                                              sampled_data =
                                                  as.data.table(sampled_data_all),
                                              return_neg = FALSE,
                                              cov_mat = NULL,
                                              cov_names = covariate_names,
                                              use_outsider_prob = FALSE,
                                              return_clust_loglikes = TRUE)
        sampled_loglike_df$prop_pos <- prop_pos
        sampled_loglike_df$B <- B
        list_df[[length(prop_pos_seq) * (ii-1) + jj]] <- sampled_loglike_df
    }
}
plot_df <- dplyr::bind_rows(list_df)
    
## Plot histogram of likelihoods
gg <- ggplot(data = plot_df,
             aes(x = like, y = ..density..)) +
    geom_histogram() +
    geom_vline(xintercept = mean(sampled_loglike_df$like),
               col = "red") +
    facet_grid(B~prop_pos) +
    scale_y_log10()
print(gg)

## Summarize
summary_df <- plot_df %>%
    group_by(B, prop_pos) %>%
    summarize(mean = mean(like),
              sd = sd(like),
              lower = quantile(like, .025),
              upper = quantile(like, .975)) %>%
    arrange(prop_pos)

summary_df %>%
    ggplot(aes(x = log10(B), y = log(mean))) +
    geom_errorbar(aes(ymin = log(lower),
                      ymax = log(upper))) +
    geom_point() +
    facet_grid(prop_pos~.) 



        
    print("Optimizing")
    init_params <- rep(0, length(covariate_names) + 1)
    bds <- rep(-5, length(covariate_names) + 1)
    cov_mat <- covariate_df_to_mat(sampled_data,
                                   cov_names = covariate_names)
    ## Now with data.table
    t1 <- proc.time()[3]
    best_params <- optim(par = init_params,
                     fn = general_loglike,
                     observed_data = tb_df,
                     sampled_data = data.table::as.data.table(sampled_data),
                     return_neg = TRUE,
                     cov_mat = cov_mat,
                     cov_names = covariate_names,
                     method = "L-BFGS-B",
                     lower = bds,
                     upper = -bds
                     )
    t2 <- proc.time()[3] - t1
    print(paste("Optimization time:", round( t2 / 60, 3),
                "min"))

    loglike_df$loglike[ii] <- - best_params$val

    ## Likelihood profile
    print("Likelihood profile")

    t1 <- proc.time()[3]

    ci_mat <- matrix(0, ncol = 2,
                     nrow = length(best_params$par))

    ci_mat <- matrix(0, ncol = 2,
                 nrow = length(best_params$par))

    for(jj in 1:nrow(ci_mat)){
        max_loglike <- -best_params$value
        best_pars <- best_params$par
        lower <- uniroot(f = like_wrapper, c(best_pars[jj] - 3, best_pars[jj]),
                         max_loglike = max_loglike,
                         best_pars = best_pars,
                         beta_index = jj,
                         sampled_data = data.table::as.data.table(sampled_data),
                         covariate_names = covariate_names,
                         cov_mat = cov_mat,
                         chi_stat = 1.92)
        ##
        upper <- uniroot(f = like_wrapper, c(best_pars[jj], best_pars[jj] + 3),
                         max_loglike = max_loglike,
                         best_pars = best_pars,
                         beta_index = jj,
                         sampled_data = data.table::as.data.table(sampled_data),
                         covariate_names = covariate_names,
                         cov_mat = cov_mat,
                         chi_stat = 1.92)

        ci_mat[jj, 1] <- lower$root
        ci_mat[jj, 2] <- upper$root
    }
    est_pars <- cbind(best_pars, ci_mat)
    rownames(est_pars) <- c("Intercept",
                            covariate_names)
    colnames(est_pars) <- c("Mean", "Lower95", "Uppper95")

    print(est_pars, digits = 2)
    t2 <- proc.time()[3] - t1

               
   print(paste("Likelihood profile time:", round( t2 / 60, 3),
               "min"))

   ll <- list(covariate_names = covariate_names,
               est_pars = est_pars)
    output_list[[ii]] <- ll

    t0f <- proc.time()[3] - t0
    print(paste("Total time:", round(t0f / 3600, 4), "hrs"))

}


loglike_df <- loglike_df %>%
    mutate(aic = 2 * (n_params) - loglike)
loglike_df


data_out <- list(loglike_df = loglike_df,
                model_list = model_list,
                output_list = output_list,
                sampled_data = sampled_data_all,
                seed = my_seed)


current_time <- Sys.time()
current_time <- gsub(" ", "_", current_time)
current_time <- gsub(":", ".", current_time)
fn_base <- paste0("data_output_", current_time, ".RDS")

saveRDS(data_out, fn_base)
